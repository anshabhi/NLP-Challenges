{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Book Names and Descriptions\n",
    "\n",
    "The approach that we are going to use is detailed string matching using built in Python Machine Learning libraries. It described as follows:\n",
    "\n",
    "* In step 1, check if any of the strings in Test Data (the book descriptions) has any of the Training data (the book names) as a substring.\n",
    "* If an exact match is found, display the match as answer for that String.\n",
    "* If exact match is not found, check if any substring of Test Data exists in Training Data. Display the answer which has maximum substrings.\n",
    "\n",
    "For implementing this, we will be using term frequencyâ€“inverse document frequency, or TF-IDF technique.\n",
    "\n",
    "#### Load the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer will convert the inpput String Into word tokens.\n",
    "TfIdfTransformer will be used to generate the TF-IDF matrix.\n",
    "Pipeline will help us to apply our algorithm, in a single step\n",
    "SVM will be used for final prediction with above matrices.\n",
    "\n",
    "### Take The inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(input())\n",
    "train = [input() for i in range(n)]\n",
    "input()\n",
    "test = [input() for i in range(n)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is self explanatory. The input is taken as required by Hackerrank.\n",
    "\n",
    "### Make and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf=Pipeline([('vect',CountVectorizer()),\n",
    "                   ('tfidf',TfidfTransformer()),\n",
    "                   ('clf',svm.SVC(gamma = 'scale'))])\n",
    "\n",
    "y=numpy.arange(n)\n",
    "\n",
    "text_clf.fit (train,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate our model as explained, in these lines of codes. `text_clf.fit()` basically trains the data on our training set.\n",
    "\n",
    "### Make predictions and Display output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=text_clf.predict(test)\n",
    "\n",
    "for i in result:\n",
    "    print(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally make the predictions and display them. The solution generated a decent score of 100/100 on hackkerrank.\n",
    "\n",
    "![Output](Capture.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
